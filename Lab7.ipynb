{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Robotics II: Control, Modeling and Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laboratory 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse Kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Zarema Balgabekova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.utils import np_utils \n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset of 5000 points was collected using dataset.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict.csv contains 5000 data points\n",
    "data = pd.read_csv(\"dict2.csv\", header = None, names = [\"Angles\", \"XY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data['Angles'].to_numpy()\n",
    "labels = data['XY'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list()\n",
    "Y = list()\n",
    "for i in range(len(train)):\n",
    "    labels[i] = labels[i].replace('   ', ' ')\n",
    "    labels[i] = labels[i].replace('  ', ' ')\n",
    "    labels[i] = labels[i].strip('[ ').strip(' ]')\n",
    "    train[i] = train[i].strip('(').strip(')')\n",
    "    result = [float(val) for val in train[i].split(',')]\n",
    "    X.append(result)\n",
    "    result = [float(val) for val in labels[i].split(' ')]\n",
    "    Y.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.delete(Y, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different regression losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 RMSE (Root mean squared error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Forward Kinematics, joint angles were used as inputs. Now, for Inverse Kinematics, we use them as outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.254764\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss=rmse, optimizer=Adam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"RMSE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that RMSE is about 4 times worth for the Inverse Kinematics than for the Forward one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 MSE (Mean squared error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.064730\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 MAE (Mean absolute error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.215991\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_absolute_error', optimizer=Adam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MAE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 MSLE (Mean squared logarithmic error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.026023\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Adam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Huber loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Huber: 0.032863\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='huber', optimizer=Adam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"Huber: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 Log cosh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log cosh: 0.032310\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='log_cosh', optimizer=Adam(0.01))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"Log cosh: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, MSLE loss should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Adam optimizer, MSLE = 0.026023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.optimizers import Ftrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.023547\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=SGD(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.031680\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Adadelta(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.028940\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=RMSprop(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.019792\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Adagrad(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.023270\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Adamax(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.015038\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 Ftrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.024667\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Ftrl(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time Nadam optimizer should be used, while Adam was used for the Forward Kinematics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Changing the number of neurons for the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.014712\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.017849\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.015817\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result is obtained with 4 neurons for the first hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Adding more hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.017534\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.028296\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of layers does not improve the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Decreasing the number of hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.021389\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.019252\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.20)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing the number of layers also does not improve the result. So, we will keep 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the size of testing data and learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Size of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.014483\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.10)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.018688\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.01))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.30)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing the size of testing data slightly improved MSLE. This could be because this way we have more data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Changing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.030059\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.1))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.10)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSLE: 0.018373\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim =2, activation = 'relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dense(5, activation='linear'))\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=Nadam(0.001))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.asarray(Y), np.asarray(X), test_size=0.10)\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 15, verbose = 0)\n",
    "scores = model.evaluate(X_test, y_test, verbose = 0) \n",
    "print(\"MSLE: %.6f\" % (scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result was obtained with the old learning rate of 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the provided parameters (neural network with two hidden layers, RMSE loss, and Adam optimizer), we obtained the following loss: $\\textbf{RMSE = 0.254764}$. \n",
    "It was discovered that MSLE significantly decreases the loss. Trying different optimizers, we came to conclusion that Nadam optimizer gives the best performance. Furthermore, changing the number of neurons for the first hidden layer to 4 and decreasing the size of testing data also improved the result. The best loss obtained is $\\textbf{MSLE = 0.014483}$. Therefore, the result was improved by 17.6 times. \n",
    "\n",
    "Overall, the loss and the obtained improvement are worse for the Inverse Kinematics than they were for the Forward one just as we expected.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
